{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge and Transform Data\n",
    "\n",
    "- Load pre-processed data from various CSV files and merge into a single dataframe\n",
    "- Check for issues such as possible duplicates and incorrect dates, and flag these rows for review\n",
    "- Transform data so that it is organized into columns consistent with the data entry tool\n",
    "- Save the cleaned data to CSV file, which will be imported to Google Sheets for manual editing by CCMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "save_csv = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_text_cols(df, cols, sep='; '):\n",
    "    \"\"\"Concatenate 2 or more text columns and deal with missing values\"\"\"\n",
    "    output = df[cols[0]].copy()\n",
    "    for col in cols[1:]:\n",
    "        output = (output.str.cat(df[col], sep=sep, na_rep='')\n",
    "                  .str.replace('^' + sep, '', regex=True)\n",
    "                  .str.replace(sep + '$', '', regex=True)\n",
    "                  .replace('', np.nan)\n",
    "                 )\n",
    "    \n",
    "    return output\n",
    "\n",
    "def clean_incident_category(s):\n",
    "    \"\"\"Utility function for standardizing the incident categories\"\"\"\n",
    "    if pd.isnull(s):\n",
    "        return np.nan\n",
    "    \n",
    "    if s == 'C' or s.startswith('C '):\n",
    "        category = 'Criminal: Unknown'\n",
    "    elif s == 'NC' or s.startswith('NC'):\n",
    "        category = 'Non-Criminal'\n",
    "    else:\n",
    "        category = np.nan\n",
    "    return category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA/QC: Removed 48 likely inaccurate publication dates\n",
      "(1000, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident_id</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>article_url</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>city_or_region</th>\n",
       "      <th>province</th>\n",
       "      <th>detailed_location</th>\n",
       "      <th>needs_review</th>\n",
       "      <th>notes</th>\n",
       "      <th>previous_tags</th>\n",
       "      <th>dup_notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>Non-Criminal</td>\n",
       "      <td>B.C. woman caught on video delivering racist r...</td>\n",
       "      <td>https://globalnews.ca/news/3949365/b-c-woman-c...</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>Burnaby</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NC; hate speech; anti-black; Burnaby</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>Non-Criminal</td>\n",
       "      <td>Windsor Muslims pen letter asking police why I...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/windsor/graffit...</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>Windsor</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NC; vandalism; anti-muslim; Windsor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>Non-Criminal</td>\n",
       "      <td>Sen. Lynn Beyak booted from Conservative caucu...</td>\n",
       "      <td>https://nationalpost.com/news/politics/sen-lyn...</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>Ottawa</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NC; hate speech; anti-indigenous; Ottawa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>Non-Criminal</td>\n",
       "      <td>Lawyers question fairness of Calgary judge acc...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/calgary/judge-e...</td>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NC; hate speech; anti-black; Calgary</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>Non-Criminal</td>\n",
       "      <td>P.E.I. legion to apologize after video shows w...</td>\n",
       "      <td>http://nationalpost.com/news/canada/p-e-i-legi...</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>Tignish</td>\n",
       "      <td>Prince Edward Island</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NC; harassment; anti-sikh/indian; Tignish</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   incident_id       date      category  \\\n",
       "0            1 2018-01-05  Non-Criminal   \n",
       "1            2 2018-01-03  Non-Criminal   \n",
       "2            3 2018-01-04  Non-Criminal   \n",
       "3            4 2018-01-09  Non-Criminal   \n",
       "4            5 2018-01-20  Non-Criminal   \n",
       "\n",
       "                                         description  \\\n",
       "0  B.C. woman caught on video delivering racist r...   \n",
       "1  Windsor Muslims pen letter asking police why I...   \n",
       "2  Sen. Lynn Beyak booted from Conservative caucu...   \n",
       "3  Lawyers question fairness of Calgary judge acc...   \n",
       "4  P.E.I. legion to apologize after video shows w...   \n",
       "\n",
       "                                         article_url publish_date  \\\n",
       "0  https://globalnews.ca/news/3949365/b-c-woman-c...   2018-01-05   \n",
       "1  https://www.cbc.ca/news/canada/windsor/graffit...   2018-01-03   \n",
       "2  https://nationalpost.com/news/politics/sen-lyn...   2018-01-05   \n",
       "3  https://www.cbc.ca/news/canada/calgary/judge-e...   2018-01-09   \n",
       "4  http://nationalpost.com/news/canada/p-e-i-legi...   2018-01-20   \n",
       "\n",
       "  city_or_region              province detailed_location needs_review notes  \\\n",
       "0        Burnaby      British Columbia               NaN          NaN   NaN   \n",
       "1        Windsor               Ontario               NaN          NaN   NaN   \n",
       "2         Ottawa               Ontario               NaN          NaN   NaN   \n",
       "3        Calgary               Alberta               NaN          NaN   NaN   \n",
       "4        Tignish  Prince Edward Island               NaN          NaN   NaN   \n",
       "\n",
       "                               previous_tags dup_notes  \n",
       "0       NC; hate speech; anti-black; Burnaby       NaN  \n",
       "1        NC; vandalism; anti-muslim; Windsor       NaN  \n",
       "2   NC; hate speech; anti-indigenous; Ottawa       NaN  \n",
       "3       NC; hate speech; anti-black; Calgary       NaN  \n",
       "4  NC; harassment; anti-sikh/indian; Tignish       NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consolidated raw data\n",
    "rr = pd.read_csv('race_relations_raw_consolidated.csv')\n",
    "rr['date'] = pd.to_datetime(rr['date'])\n",
    "\n",
    "# Cleaned incident locations\n",
    "locations = (pd.read_csv('Locations/incident_locations.csv')\n",
    "             .drop(['article_url', 'national'], axis=1)\n",
    "            )  \n",
    "\n",
    "# Article publication dates scraped from each URL\n",
    "pub_dates = pd.read_csv('Publication date/publish_dates.csv')\n",
    "pub_dates['publish_date'] = pd.to_datetime(pub_dates['publish_date'])\n",
    "cols = ['incident_id', 'article_url']\n",
    "if not pub_dates[cols].equals(rr[cols]):\n",
    "    raise ValueError('Incident IDs or URLs inconsistent between publication dates dataframe and main dataframe')\n",
    "\n",
    "# Merge dataframes\n",
    "rr = (rr.merge(pub_dates.drop('article_url', axis=1), on='incident_id', how='outer')\n",
    "      .merge(locations, on='incident_id', how='outer')\n",
    "     )\n",
    "\n",
    "# Add detailed locations for the few incidents where it can be easily parsed from the description\n",
    "detailed_locs = ['Fort McMurray Islamic Centre', 'South West Detention Centre', 'Brock University',\n",
    "                 'Brantford Mosque', 'University of Manitoba', 'Laurentian University', 'Nipissing University',\n",
    "                 'University of Saskatchewan', 'University of New Brunswick', 'London Muslim Mosque', \n",
    "                 'Eaton Centre', 'York University', \"Queen's University\", 'Chinese Cultural Centre', \n",
    "                 'Canadian Museum for Human Rights', 'McMaster University']\n",
    "for val in detailed_locs:\n",
    "    rr.loc[rr['description'].str.contains(val, case=False).fillna(False), 'detailed_location'] = val\n",
    "    \n",
    "# Rough fix to remove obvious inaccuracies in publication dates\n",
    "date1 = pd.to_datetime('2020-01-01')\n",
    "date2 = pd.to_datetime('2020-08-01')\n",
    "idx_remove = (rr['publish_date'] > date1) & (rr['date'] < date1)\n",
    "idx_remove = idx_remove | (rr['publish_date'] > date2) & (rr['date'] < date2)\n",
    "idx_remove = idx_remove | (rr['publish_date'] < rr['date'].min())\n",
    "rr.loc[idx_remove, 'publish_date'] = np.nan\n",
    "print(f'QA/QC: Removed {idx_remove.sum()} likely inaccurate publication dates')\n",
    "\n",
    "# Consolidate all previous tags into one column\n",
    "cols = ['category', 'sub_category', 'target_community', 'location']\n",
    "rr['previous_tags'] = concatenate_text_cols(rr, cols)\n",
    "\n",
    "# Standardize the incident category column\n",
    "rr['category'] = rr['category'].apply(clean_incident_category)\n",
    "\n",
    "# Specify whether there were charges associated with a crime if this info was\n",
    "# provided in the previous tags, otherwise leave as Criminal: Other\n",
    "charges = {\n",
    "    \"victim didn’t file a charge\": 'Criminal: Not charged',\n",
    "    'not charged': 'Criminal: Not charged',\n",
    "    'Charged with mischief' : 'Criminal: Charged',\n",
    "    'forgery charges' : 'Criminal: Charged'\n",
    "}\n",
    "for sub_str, category in charges.items():\n",
    "    rr.loc[rr['previous_tags'].str.contains(sub_str), 'category'] = category\n",
    "\n",
    "# Possible duplicate entries\n",
    "grouped = rr[rr.duplicated(subset=['article_url'], keep=False)].groupby('article_url')\n",
    "dup_labels = {}\n",
    "for i, (url, df) in enumerate(grouped, start=1):\n",
    "    group_ids = df.reset_index()['incident_id'].astype(str).to_list()\n",
    "    group_str = f'Group {i:02d}: URL duplicated in multiple incidents'\n",
    "    dup_labels.update({int(n) : group_str for n in group_ids})\n",
    "\n",
    "rr['dup_notes'] = rr['incident_id'].map(dup_labels)\n",
    "rr.loc[rr['dup_notes'].notnull(), 'dup_flag'] = 'Possible duplicate incident'\n",
    "\n",
    "# Check for dates where the year is inconsistent with the sheet name\n",
    "idx_check_date = rr['year'] != rr['orig_sheet_name'].str[:4].astype(int)\n",
    "rr.loc[idx_check_date, 'date_flag'] = 'Check date'\n",
    "rr.loc[idx_check_date, 'date_notes'] = 'Date could not be parsed or listed date is inconsistent with year in original sheet name'\n",
    "\n",
    "# Check for entries with multiple article URLs\n",
    "idx_url = rr['article_url'].str.contains(' ') | rr['article_url'].str.contains('\\n')\n",
    "rr.loc[idx_url, 'url_flag'] = 'Invalid Article URL'\n",
    "rr.loc[idx_url, 'url_notes'] = 'Multiple URLs listed - remove extras so there is only one for this incident'\n",
    "\n",
    "# Concatenate additional data flags and notes\n",
    "rr['needs_review'] = concatenate_text_cols(rr, ['dup_flag', 'date_flag', 'url_flag', 'needs_review'])\n",
    "rr['notes'] = concatenate_text_cols(rr, ['dup_notes', 'date_notes', 'url_notes', 'notes'])\n",
    "\n",
    "# Drop unneeded columns\n",
    "drop_cols = ['location', 'sub_category', 'target_community', 'year', 'orig_sheet_name', 'orig_row_num',\n",
    "             'date_flag', 'date_notes', 'dup_flag', 'url_flag', 'url_notes']\n",
    "rr = rr.drop(drop_cols, axis=1)\n",
    "\n",
    "print(rr.shape)\n",
    "rr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n",
    "\n",
    "Map the old tags from the original data into the columns and tags of the new taxonomy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2536, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident_id</th>\n",
       "      <th>Previous Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>anti-black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hate speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>anti-muslim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>vandalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>anti-indigenous</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   incident_id     Previous Tag\n",
       "0            1       anti-black\n",
       "1            1      hate speech\n",
       "2            2      anti-muslim\n",
       "3            2        vandalism\n",
       "4            3  anti-indigenous"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previous tags for each incident\n",
    "tags_old = (pd.read_csv('Pre-Processing/tags_all.csv')\n",
    "            .drop('variable', axis=1)\n",
    "            .drop_duplicates()\n",
    "            .reset_index(drop=True)\n",
    "            .rename({'tag' : 'Previous Tag'}, axis=1)\n",
    "           )\n",
    "print(tags_old.shape)\n",
    "tags_old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Previous Tag</th>\n",
       "      <th>Ethnic Community</th>\n",
       "      <th>Black/African/Caribbean</th>\n",
       "      <th>Central Asian</th>\n",
       "      <th>East Asian</th>\n",
       "      <th>Indigenous</th>\n",
       "      <th>Latin American</th>\n",
       "      <th>Middle Eastern</th>\n",
       "      <th>South Asian</th>\n",
       "      <th>Southeast Asian</th>\n",
       "      <th>Identity-Based</th>\n",
       "      <th>Context</th>\n",
       "      <th>Type of Incident</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allegations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allegations against police</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Protective services: Police</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anti-afghan</td>\n",
       "      <td>Central Asian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anti-african</td>\n",
       "      <td>Black/African/Caribbean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anti-arab</td>\n",
       "      <td>Middle Eastern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Previous Tag         Ethnic Community  \\\n",
       "0                 allegations                      NaN   \n",
       "1  allegations against police                      NaN   \n",
       "2                 anti-afghan            Central Asian   \n",
       "3                anti-african  Black/African/Caribbean   \n",
       "4                   anti-arab           Middle Eastern   \n",
       "\n",
       "   Black/African/Caribbean Central Asian East Asian  Indigenous  \\\n",
       "0                      NaN           NaN        NaN         NaN   \n",
       "1                      NaN           NaN        NaN         NaN   \n",
       "2                      NaN   Afghanistan        NaN         NaN   \n",
       "3                      NaN           NaN        NaN         NaN   \n",
       "4                      NaN           NaN        NaN         NaN   \n",
       "\n",
       "  Latin American Middle Eastern South Asian Southeast Asian Identity-Based  \\\n",
       "0            NaN            NaN         NaN             NaN            NaN   \n",
       "1            NaN            NaN         NaN             NaN            NaN   \n",
       "2            NaN            NaN         NaN             NaN            NaN   \n",
       "3            NaN            NaN         NaN             NaN            NaN   \n",
       "4            NaN            NaN         NaN             NaN            NaN   \n",
       "\n",
       "                       Context Type of Incident  \n",
       "0                          NaN              NaN  \n",
       "1  Protective services: Police              NaN  \n",
       "2                          NaN              NaN  \n",
       "3                          NaN              NaN  \n",
       "4                          NaN              NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lookup table to map old tags to the taxonomy\n",
    "lookup = pd.read_csv('Pre-Processing/tags_lookup.csv')\n",
    "print(lookup.shape)\n",
    "lookup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches(rr, tags_dict, tag_name='Context', drop_duplicates=False, case=False):\n",
    "    \"\"\"Find sub-string matches in incident description and assign new tags\"\"\"\n",
    "    extra_tags = pd.DataFrame()\n",
    "    for tag, pattern in tags_dict.items():\n",
    "        matches = rr.loc[rr['description'].str.contains(pattern, case=case).fillna(False), 'incident_id']\n",
    "        extra_tags = extra_tags.append(pd.DataFrame({'incident_id' : matches.values, tag_name : tag}))\n",
    "\n",
    "    if drop_duplicates:\n",
    "        extra_tags = extra_tags.drop_duplicates(subset=['incident_id'], keep='first')\n",
    "        \n",
    "    return extra_tags\n",
    "\n",
    "\n",
    "def smush_tags(df, columns, by='incident_id', sep=', ', sort=True):\n",
    "    \"\"\"Smush tags on multiple rows into one row of comma-separated tags per incident\"\"\"\n",
    "    \n",
    "    def smush(vals, sep):\n",
    "        parts = vals[vals.notnull()].unique()\n",
    "        if sort:\n",
    "            parts = sorted(parts)\n",
    "        output = sep.join(parts)\n",
    "        if output == '':\n",
    "            output = np.nan\n",
    "        return output\n",
    "    \n",
    "    df_out = pd.DataFrame()\n",
    "    for col in columns:\n",
    "        df_out[col] = df.groupby(by)[col].agg(smush, sep=sep)\n",
    "        \n",
    "    df_out = df_out.reset_index(drop=False)\n",
    "        \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(904, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident_id</th>\n",
       "      <th>Ethnic Community</th>\n",
       "      <th>Black/African/Caribbean</th>\n",
       "      <th>Central Asian</th>\n",
       "      <th>East Asian</th>\n",
       "      <th>Indigenous</th>\n",
       "      <th>Latin American</th>\n",
       "      <th>Middle Eastern</th>\n",
       "      <th>South Asian</th>\n",
       "      <th>Southeast Asian</th>\n",
       "      <th>Identity-Based</th>\n",
       "      <th>Context</th>\n",
       "      <th>Type of Incident</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Black/African/Caribbean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hate speech: Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Religious discrimination: Islamophobia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vandalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Indigenous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Online: Other</td>\n",
       "      <td>Hate speech: Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Black/African/Caribbean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hate speech: Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>South Asian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Religious discrimination: Anti-Sikhism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Harassment: Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   incident_id         Ethnic Community  Black/African/Caribbean  \\\n",
       "0            1  Black/African/Caribbean                      NaN   \n",
       "1            2                      NaN                      NaN   \n",
       "2            3               Indigenous                      NaN   \n",
       "3            4  Black/African/Caribbean                      NaN   \n",
       "4            5              South Asian                      NaN   \n",
       "\n",
       "  Central Asian East Asian  Indigenous Latin American Middle Eastern  \\\n",
       "0           NaN        NaN         NaN            NaN            NaN   \n",
       "1           NaN        NaN         NaN            NaN            NaN   \n",
       "2           NaN        NaN         NaN            NaN            NaN   \n",
       "3           NaN        NaN         NaN            NaN            NaN   \n",
       "4           NaN        NaN         NaN            NaN            NaN   \n",
       "\n",
       "  South Asian Southeast Asian                          Identity-Based  \\\n",
       "0         NaN             NaN                                     NaN   \n",
       "1         NaN             NaN  Religious discrimination: Islamophobia   \n",
       "2         NaN             NaN                                     NaN   \n",
       "3         NaN             NaN                                     NaN   \n",
       "4       India             NaN  Religious discrimination: Anti-Sikhism   \n",
       "\n",
       "         Context    Type of Incident  \n",
       "0            NaN  Hate speech: Other  \n",
       "1            NaN           Vandalism  \n",
       "2  Online: Other  Hate speech: Other  \n",
       "3            NaN  Hate speech: Other  \n",
       "4            NaN   Harassment: Other  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map old tags to taxonomy\n",
    "tags = tags_old.merge(lookup, on='Previous Tag', how='left')\n",
    "\n",
    "# Add other tags based on info in the incident description\n",
    "online = {\n",
    "    'Online: Social media' : 'social.media|facebook|twitter|forum|iron march',\n",
    "    'Online: Other' : 'webinar|website|gofundme|online'\n",
    "}\n",
    "\n",
    "edu = {\n",
    "    'Educational institute: K-12' : 'elementary school|middle school|high school|secondary school',\n",
    "    'Educational institute: Post-secondary' : 'university|college|law school',\n",
    "    'Educational institute: Other' : 'school|teacher'\n",
    "}\n",
    "\n",
    "other_contexts = {\n",
    "    'Healthcare/public health' : 'health.?care|health services|hospital',\n",
    "    'Sports: Hockey' : 'hockey',\n",
    "    'Sports: Basketball' : 'basketball',\n",
    "    'Sports: Football' : 'football',\n",
    "    'Transit' : 'transit|\\Wbus\\W|^bus\\W|\\Wbus$|subway',\n",
    "    'Workplace' : 'worksite|workplace|work environment|at work'\n",
    "}\n",
    "\n",
    "types = {\n",
    "    'Hate speech: Rally/protest' : 'anti-immigration rally|white nationalist rally',\n",
    "    'Hate speech: Letter/flyer' : 'flyer|anti-semitic letter|anti-arab letter|racist.*letter|letter.*racist|troubling.*letter|controversial letter',\n",
    "    'Hate speech: Imagery' : 'image'\n",
    "}\n",
    "\n",
    "tags = tags.append(find_matches(rr, online, tag_name='Context', drop_duplicates=True))\n",
    "tags = tags.append(find_matches(rr, edu, tag_name='Context', drop_duplicates=True))\n",
    "tags = tags.append(find_matches(rr, other_contexts, tag_name='Context'))\n",
    "tags = tags.append(find_matches(rr, types, tag_name='Type of Incident'))\n",
    "\n",
    "# Only keep rows which have at least one value in the taxonomy\n",
    "new_cols = lookup.drop('Previous Tag', axis=1).columns.to_list()\n",
    "tags = tags[tags[new_cols].any(axis=1)]\n",
    "\n",
    "# Collapse into one row per incident\n",
    "tags = smush_tags(tags, columns=new_cols)\n",
    "\n",
    "# Manually remove extraneous tags for letter/flyer incidents\n",
    "tags['Type of Incident'] = tags['Type of Incident'].replace({'Hate speech: Letter/flyer, Hate speech: Other' : 'Hate speech: Letter/flyer'})\n",
    "\n",
    "print(tags.shape)\n",
    "tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Incident ID</th>\n",
       "      <th>Article URL</th>\n",
       "      <th>Incident Description</th>\n",
       "      <th>Publication Date</th>\n",
       "      <th>Incident Date</th>\n",
       "      <th>Pub Date Minus Incident Date</th>\n",
       "      <th>Province</th>\n",
       "      <th>City or Region</th>\n",
       "      <th>Detailed Location</th>\n",
       "      <th>Incident Category</th>\n",
       "      <th>...</th>\n",
       "      <th>South Asian</th>\n",
       "      <th>Southeast Asian</th>\n",
       "      <th>Identity-Based</th>\n",
       "      <th>Context</th>\n",
       "      <th>Type of Incident</th>\n",
       "      <th>Previous Tags</th>\n",
       "      <th>Needs Review</th>\n",
       "      <th>D4G Notes</th>\n",
       "      <th>CCMF Notes</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>169</td>\n",
       "      <td>https://www.cbc.ca/news/canada/british-columbi...</td>\n",
       "      <td>RCMP are looking for a group of fishermen accu...</td>\n",
       "      <td>2018-08-29</td>\n",
       "      <td>2018-08-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Hope</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Criminal: Unknown</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C; race relations; anti-indigenous; Fraser Riv...</td>\n",
       "      <td>Check city</td>\n",
       "      <td>Location originally listed as Fraser River, wh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>831</td>\n",
       "      <td>https://www.theglobeandmail.com/politics/artic...</td>\n",
       "      <td>Conservative leadership candidate, who was dis...</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Criminal</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Religious discrimination: Islamophobia</td>\n",
       "      <td>Politics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NC; political; anti-muslim; Cambridge</td>\n",
       "      <td>Check city</td>\n",
       "      <td>No mention of the city of Cambridge in the art...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Incident ID                                        Article URL  \\\n",
       "0          169  https://www.cbc.ca/news/canada/british-columbi...   \n",
       "1          831  https://www.theglobeandmail.com/politics/artic...   \n",
       "\n",
       "                                Incident Description Publication Date  \\\n",
       "0  RCMP are looking for a group of fishermen accu...       2018-08-29   \n",
       "1  Conservative leadership candidate, who was dis...       2020-03-24   \n",
       "\n",
       "  Incident Date  Pub Date Minus Incident Date          Province  \\\n",
       "0    2018-08-29                           0.0  British Columbia   \n",
       "1    2020-03-24                           0.0           Ontario   \n",
       "\n",
       "  City or Region Detailed Location  Incident Category  ...  South Asian  \\\n",
       "0           Hope               NaN  Criminal: Unknown  ...          NaN   \n",
       "1      Cambridge               NaN       Non-Criminal  ...          NaN   \n",
       "\n",
       "   Southeast Asian                          Identity-Based   Context  \\\n",
       "0              NaN                                     NaN       NaN   \n",
       "1              NaN  Religious discrimination: Islamophobia  Politics   \n",
       "\n",
       "  Type of Incident                                      Previous Tags  \\\n",
       "0              NaN  C; race relations; anti-indigenous; Fraser Riv...   \n",
       "1              NaN              NC; political; anti-muslim; Cambridge   \n",
       "\n",
       "  Needs Review                                          D4G Notes CCMF Notes  \\\n",
       "0   Check city  Location originally listed as Fraser River, wh...        NaN   \n",
       "1   Check city  No mention of the city of Cambridge in the art...        NaN   \n",
       "\n",
       "  Status  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge with main dataframe and sort so that duplicate URL groups are together and \n",
    "# all entries flagged for review are at the top\n",
    "rr_clean = (rr.drop(new_cols, errors='ignore')\n",
    "            .merge(tags, on='incident_id', how='outer')\n",
    "            .sort_values(['needs_review', 'dup_notes', 'incident_id'])\n",
    "            .drop('dup_notes', axis=1)\n",
    "            .reset_index(drop=True)\n",
    "           )\n",
    "\n",
    "# Rename columns\n",
    "names_dict = {\n",
    "    'incident_id' : 'Incident ID',\n",
    "    'date' : 'Incident Date',\n",
    "    'category' : 'Incident Category',\n",
    "    'description' : 'Incident Description',\n",
    "    'article_url' : 'Article URL',\n",
    "    'city_or_region' : 'City or Region',\n",
    "    'province' : 'Province',\n",
    "    'detailed_location' : 'Detailed Location',\n",
    "    'needs_review' : 'Needs Review',\n",
    "    'notes' : 'D4G Notes',\n",
    "    'previous_tags' : 'Previous Tags',\n",
    "    'publish_date' : 'Publication Date'\n",
    "}\n",
    "\n",
    "rr_clean = rr_clean.rename(names_dict, axis=1)\n",
    "\n",
    "# Add column with difference between publication date and incident date\n",
    "rr_clean['Pub Date Minus Incident Date'] = (rr_clean['Publication Date'] - rr_clean['Incident Date']).dt.days\n",
    "\n",
    "# Fill some of the missing ethnic communities\n",
    "fill_values = [\n",
    "    ('Nigeria', 'Nigeria', 'Black/African/Caribbean'),\n",
    "    ('Somali', 'Somalia', 'Black/African/Caribbean'),\n",
    "    ('Iran', 'Iran', 'Central Asian'),\n",
    "    ('Inuit', 'Inuit', 'Indigenous'),\n",
    "    ('Egypt', 'Egypt', 'Middle Eastern')\n",
    "]\n",
    "\n",
    "for pattern, sub_community, community in fill_values:\n",
    "    idx = rr_clean['Incident Description'].str.contains(pattern).fillna(False)\n",
    "    rr_clean.loc[idx, 'Ethnic Community'] = rr_clean.loc[idx, 'Ethnic Community'].fillna(community)\n",
    "    rr_clean.loc[idx, community] = rr_clean.loc[idx, community].fillna(sub_community)\n",
    "\n",
    "# Add empty columns for manual data entry\n",
    "cols_extra = ['Gender of Victim(s)', 'Name of Victim(s)', 'CCMF Notes', 'Status']\n",
    "for col in cols_extra:\n",
    "    rr_clean[col] = np.nan\n",
    "\n",
    "# Re-order columns\n",
    "cols = rr_clean.columns.to_list()\n",
    "cols_out = ['Incident ID', 'Article URL', 'Incident Description', 'Publication Date',  'Incident Date', \n",
    "            'Pub Date Minus Incident Date', 'Province', 'City or Region', \n",
    "            'Detailed Location', 'Incident Category', 'Gender of Victim(s)', 'Name of Victim(s)',\n",
    "            ]\n",
    "cols_out += new_cols\n",
    "cols_out += ['Previous Tags', 'Needs Review', 'D4G Notes', 'CCMF Notes', 'Status']\n",
    "\n",
    "rr_clean = rr_clean[cols_out]\n",
    "print(rr_clean.shape)\n",
    "rr_clean.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 29 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   Incident ID                   1000 non-null   int64         \n",
      " 1   Article URL                   1000 non-null   object        \n",
      " 2   Incident Description          999 non-null    object        \n",
      " 3   Publication Date              823 non-null    datetime64[ns]\n",
      " 4   Incident Date                 997 non-null    datetime64[ns]\n",
      " 5   Pub Date Minus Incident Date  820 non-null    float64       \n",
      " 6   Province                      941 non-null    object        \n",
      " 7   City or Region                852 non-null    object        \n",
      " 8   Detailed Location             26 non-null     object        \n",
      " 9   Incident Category             734 non-null    object        \n",
      " 10  Gender of Victim(s)           0 non-null      float64       \n",
      " 11  Name of Victim(s)             0 non-null      float64       \n",
      " 12  Ethnic Community              472 non-null    object        \n",
      " 13  Black/African/Caribbean       3 non-null      object        \n",
      " 14  Central Asian                 5 non-null      object        \n",
      " 15  East Asian                    29 non-null     object        \n",
      " 16  Indigenous                    3 non-null      object        \n",
      " 17  Latin American                1 non-null      object        \n",
      " 18  Middle Eastern                5 non-null      object        \n",
      " 19  South Asian                   20 non-null     object        \n",
      " 20  Southeast Asian               4 non-null      object        \n",
      " 21  Identity-Based                313 non-null    object        \n",
      " 22  Context                       365 non-null    object        \n",
      " 23  Type of Incident              437 non-null    object        \n",
      " 24  Previous Tags                 1000 non-null   object        \n",
      " 25  Needs Review                  55 non-null     object        \n",
      " 26  D4G Notes                     55 non-null     object        \n",
      " 27  CCMF Notes                    0 non-null      float64       \n",
      " 28  Status                        0 non-null      float64       \n",
      "dtypes: datetime64[ns](2), float64(5), int64(1), object(21)\n",
      "memory usage: 226.7+ KB\n"
     ]
    }
   ],
   "source": [
    "rr_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Incident Category ------\n",
      "Non-Criminal             640\n",
      "NaN                      266\n",
      "Criminal: Unknown         90\n",
      "Criminal: Not charged      2\n",
      "Criminal: Charged          2\n",
      "Name: Incident Category, dtype: int64\n",
      "\n",
      "---- Gender of Victim(s) ------\n",
      "NaN    1000\n",
      "Name: Gender of Victim(s), dtype: int64\n",
      "\n",
      "---- Ethnic Community ------\n",
      "NaN                                                    528\n",
      "Black/African/Caribbean                                207\n",
      "Indigenous                                             177\n",
      "East Asian                                              27\n",
      "South Asian                                             22\n",
      "Middle Eastern                                           8\n",
      "Black/African/Caribbean, Indigenous                      7\n",
      "Black/African/Caribbean, Indigenous, Middle Eastern      7\n",
      "Central Asian                                            5\n",
      "Southeast Asian                                          4\n",
      "Black/African/Caribbean, South Asian                     3\n",
      "Latin American                                           2\n",
      "Indigenous, Middle Eastern                               1\n",
      "East Asian, Indigenous                                   1\n",
      "Black/African/Caribbean, East Asian                      1\n",
      "Name: Ethnic Community, dtype: int64\n",
      "\n",
      "---- Black/African/Caribbean ------\n",
      "NaN        997\n",
      "Nigeria      2\n",
      "Somalia      1\n",
      "Name: Black/African/Caribbean, dtype: int64\n",
      "\n",
      "---- Central Asian ------\n",
      "NaN            995\n",
      "Iran             3\n",
      "Afghanistan      2\n",
      "Name: Central Asian, dtype: int64\n",
      "\n",
      "---- East Asian ------\n",
      "NaN       971\n",
      "China      28\n",
      "Taiwan      1\n",
      "Name: East Asian, dtype: int64\n",
      "\n",
      "---- Indigenous ------\n",
      "NaN      997\n",
      "Inuit      3\n",
      "Name: Indigenous, dtype: int64\n",
      "\n",
      "---- Latin American ------\n",
      "NaN       999\n",
      "Mexico      1\n",
      "Name: Latin American, dtype: int64\n",
      "\n",
      "---- Middle Eastern ------\n",
      "NaN                  995\n",
      "Palestine              2\n",
      "Syria                  1\n",
      "Egypt                  1\n",
      "Israel, Palestine      1\n",
      "Name: Middle Eastern, dtype: int64\n",
      "\n",
      "---- South Asian ------\n",
      "NaN         980\n",
      "India        19\n",
      "Pakistan      1\n",
      "Name: South Asian, dtype: int64\n",
      "\n",
      "---- Southeast Asian ------\n",
      "NaN            996\n",
      "Philippines      4\n",
      "Name: Southeast Asian, dtype: int64\n",
      "\n",
      "---- Identity-Based ------\n",
      "NaN                                                                                                                                687\n",
      "Religious discrimination: Islamophobia                                                                                              97\n",
      "Religious discrimination: Anti-Semitism                                                                                             79\n",
      "Xenophobia                                                                                                                          58\n",
      "Religious discrimination: Anti-Sikhism                                                                                              14\n",
      "Sexism                                                                                                                              12\n",
      "Anti-2SLGBTQIA+                                                                                                                     12\n",
      "Religious discrimination: Islamophobia, Xenophobia                                                                                  12\n",
      "Religious discrimination: Anti-Semitism, Religious discrimination: Islamophobia                                                      9\n",
      "Religious discrimination: Anti-Sikhism, Religious discrimination: Islamophobia                                                       4\n",
      "Religious discrimination: Islamophobia, Sexism                                                                                       3\n",
      "Anti-2SLGBTQIA+, Xenophobia                                                                                                          2\n",
      "Religious discrimination: Anti-Semitism, Religious discrimination: Anti-Sikhism, Religious discrimination: Islamophobia, Sexism      2\n",
      "Anti-2SLGBTQIA+, Religious discrimination: Islamophobia                                                                              2\n",
      "Religious discrimination: Anti-Semitism, Xenophobia                                                                                  2\n",
      "Religious discrimination: Anti-Semitism, Religious discrimination: Islamophobia, Xenophobia                                          1\n",
      "Religious discrimination: Anti-Semitism, Religious discrimination: Anti-Sikhism, Religious discrimination: Islamophobia              1\n",
      "Sexism, Xenophobia                                                                                                                   1\n",
      "Anti-2SLGBTQIA+, Religious discrimination: Anti-Semitism, Religious discrimination: Islamophobia                                     1\n",
      "Religious discrimination: Anti-Semitism, Sexism                                                                                      1\n",
      "Name: Identity-Based, dtype: int64\n",
      "\n",
      "---- Context ------\n",
      "NaN                                                            635\n",
      "Politics                                                       159\n",
      "Educational institute: Other                                    44\n",
      "Online: Social media                                            36\n",
      "Sports: Hockey                                                  17\n",
      "Educational institute: Post-secondary                           16\n",
      "Transit                                                         15\n",
      "Online: Other                                                   12\n",
      "Educational institute: K-12                                      9\n",
      "Healthcare/public health                                         7\n",
      "Online: Social media, Politics                                   7\n",
      "Online: Other, Politics                                          6\n",
      "Educational institute: Other, Politics                           6\n",
      "Workplace                                                        5\n",
      "Protective services: Military                                    5\n",
      "Protective services: Police                                      4\n",
      "Online: Social media, Protective services: Military              2\n",
      "Sports: Basketball                                               2\n",
      "Politics, Protective services: Military                          2\n",
      "Educational institute: Other, Online: Social media               2\n",
      "Educational institute: Other, Online: Other                      1\n",
      "Educational institute: Other, Transit                            1\n",
      "Environmental racism, Politics                                   1\n",
      "Online: Other, Protective services: Military                     1\n",
      "Educational institute: Post-secondary, Sports: Hockey            1\n",
      "Educational institute: Post-secondary, Online: Social media      1\n",
      "Environmental racism                                             1\n",
      "Politics, Transit                                                1\n",
      "Online: Other, Transit                                           1\n",
      "Name: Context, dtype: int64\n",
      "\n",
      "---- Type of Incident ------\n",
      "NaN                                              563\n",
      "Hate speech: Other                               221\n",
      "Vandalism                                         86\n",
      "Harassment: Racial profiling                      67\n",
      "Harassment: Other                                 28\n",
      "Hate speech: Letter/flyer                         17\n",
      "Harassment: Other, Hate speech: Other              7\n",
      "Hate speech: Imagery                               3\n",
      "Hate speech: Other, Vandalism                      3\n",
      "Harassment: Other, Hate speech: Letter/flyer       2\n",
      "Harassment: Other, Hate speech: Rally/protest      1\n",
      "Hate speech: Rally/protest                         1\n",
      "Hate speech: Letter/flyer, Vandalism               1\n",
      "Name: Type of Incident, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['Incident Category', 'Gender of Victim(s)'] + new_cols\n",
    "for col in cols:\n",
    "    print('---- ' + col + ' ------')\n",
    "    print(rr_clean[col].value_counts(dropna=False))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand Columns\n",
    "\n",
    "Create an expanded version of the dataset, to facilitate the manual revision process, where comma-separated values are split into separate columns, and with separate year, month, day columns for the incident date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(series, sep=', '):\n",
    "    \"\"\"Split a series of comma-separated values into separate columns\"\"\"\n",
    "    name = series.name\n",
    "    expanded = series.str.split(sep, expand=True).replace({None: np.nan})\n",
    "    columns = expanded.columns\n",
    "    expanded.columns = [f'{name} {n + 1}' for n in columns]\n",
    "    \n",
    "    return expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 38 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   Incident ID                   1000 non-null   int64         \n",
      " 1   Article URL                   1000 non-null   object        \n",
      " 2   Incident Description          999 non-null    object        \n",
      " 3   Publication Date              823 non-null    datetime64[ns]\n",
      " 4   Incident Date                 997 non-null    datetime64[ns]\n",
      " 5   Month Only                    0 non-null      float64       \n",
      " 6   Pub Date Minus Incident Date  820 non-null    float64       \n",
      " 7   Province                      941 non-null    object        \n",
      " 8   City or Region                852 non-null    object        \n",
      " 9   Detailed Location             26 non-null     object        \n",
      " 10  Incident Category             734 non-null    object        \n",
      " 11  Gender of Victim(s) 1         0 non-null      float64       \n",
      " 12  Gender of Victim(s) 2         0 non-null      float64       \n",
      " 13  Name of Victim(s)             0 non-null      float64       \n",
      " 14  Ethnic Community 1            472 non-null    object        \n",
      " 15  Ethnic Community 2            20 non-null     object        \n",
      " 16  Ethnic Community 3            7 non-null      object        \n",
      " 17  Black/African/Caribbean       3 non-null      object        \n",
      " 18  Central Asian                 5 non-null      object        \n",
      " 19  East Asian                    29 non-null     object        \n",
      " 20  Indigenous                    3 non-null      object        \n",
      " 21  Latin American                1 non-null      object        \n",
      " 22  Middle Eastern                5 non-null      object        \n",
      " 23  South Asian                   20 non-null     object        \n",
      " 24  Southeast Asian               4 non-null      object        \n",
      " 25  Identity-Based 1              313 non-null    object        \n",
      " 26  Identity-Based 2              41 non-null     object        \n",
      " 27  Identity-Based 3              5 non-null      object        \n",
      " 28  Identity-Based 4              2 non-null      object        \n",
      " 29  Context 1                     365 non-null    object        \n",
      " 30  Context 2                     33 non-null     object        \n",
      " 31  Type of Incident 1            437 non-null    object        \n",
      " 32  Type of Incident 2            14 non-null     object        \n",
      " 33  Previous Tags                 1000 non-null   object        \n",
      " 34  Needs Review                  55 non-null     object        \n",
      " 35  D4G Notes                     55 non-null     object        \n",
      " 36  CCMF Notes                    0 non-null      float64       \n",
      " 37  Status                        0 non-null      float64       \n",
      "dtypes: datetime64[ns](2), float64(7), int64(1), object(28)\n",
      "memory usage: 297.0+ KB\n"
     ]
    }
   ],
   "source": [
    "rr_expand = rr_clean.copy()\n",
    "\n",
    "# Column to flag approximate incident dates\n",
    "rr_expand.insert(5, 'Month Only', [np.nan] * rr_clean.shape[0])\n",
    "\n",
    "# Add a second gender column in case more than one victim\n",
    "rr_expand = rr_expand.rename({'Gender of Victim(s)' : 'Gender of Victim(s) 1'}, axis=1)\n",
    "rr_expand.insert(12, 'Gender of Victim(s) 2', [np.nan] * rr_clean.shape[0])\n",
    "\n",
    "# Split comma-separated values into separate columns\n",
    "cols_split = ['Ethnic Community', 'Identity-Based', 'Context', 'Type of Incident']\n",
    "rr_expand = rr_expand.drop(cols_split, axis=1)\n",
    "for col in cols_split:\n",
    "    rr_expand = rr_expand.join(split(rr_clean[col]))\n",
    "    \n",
    "# Re-order columns\n",
    "cols = rr_expand.columns.to_list()\n",
    "cols_out = cols[:14] + cols[27:30] + cols[14:22] + cols[30:] + cols[22:27]\n",
    "rr_expand = rr_expand[cols_out]\n",
    "\n",
    "rr_expand.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, savefile, index=False, float_format='%.0f'):\n",
    "    print(f'Saving to {savefile}')\n",
    "    data.to_csv(savefile, index=index, float_format=float_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to race_relations_clean_prelim.csv\n",
      "Saving to race_relations_clean_prelim_expanded_columns.csv\n"
     ]
    }
   ],
   "source": [
    "if save_csv:\n",
    "    save_data(rr_clean, 'race_relations_clean_prelim.csv')\n",
    "    save_data(rr_expand, 'race_relations_clean_prelim_expanded_columns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
